batch_size: 24
device: '1'
dropout: 0.1
epochs: 10
eval_per_epochs: 1
freeze_text: 1
gpu: true
head: 2
hidden_dim: 256
loss_weight: 0.7
lr: 5.0e-05
max_sequence_length: 1024
output_folder_name: ./model/20231110-124244_deberta-large_msl-1024/
pretrained_text: microsoft/deberta-large
qa_dim: 1024
seed_value: 42
text_dim: 1024
text_model_gpu: true
val_accurancy: 0.72578
val_f1: 0.72456
