batch_size: 24
device: '1'
dropout: 0.1
epochs: 15
eval_per_epochs: 1
freeze_text: 1
gpu: true
head: 2
hidden_dim: 256
loss_weight: 0.7
lr: 5.0e-05
max_len: 32000
max_sequence_length: 512
output_folder_name: ./model/20231122-203710_deberta-v3-large_ml-32000/
pretrained_text: microsoft/deberta-v3-large
qa_dim: 1024
seed_value: 42
text_dim: 1024
text_model_gpu: true
total_loss: 392.12762397527695
val_accurancy: 0.62756
val_f1: 0.54917
